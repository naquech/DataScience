{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Recommendation System\n",
    "\n",
    "## Introduction\n",
    "In this lab, we are going to use Amazon Product Co-purchase data to make Book Recommendations using Social Network Analysis Techniques. We shall make use of the concepts covered in this section towards centrality and clustering dynamics of a graph. In particular, we'll make use of the \"Island Method\" for networks analysis to split the huge graph into smaller islands for identifying similarity between books. \n",
    "\n",
    "## Objectives\n",
    "You will be able to: \n",
    "\n",
    "* Read and manipulate graph data and get it ready for analysis\n",
    "* Apply Network Analysis and graph dynamics concepts to analyze complex networks\n",
    "* Build a recommendation system using the graph data for complex networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Based Recommendation Systems \n",
    "From purchase suggestions on e-commerce websites to content customization on multimedia platforms, recommender systems happen to be more and more widespread among the web. Modern companies such as Facebook, Netflix, Amazon all develop their own, aiming to propose items or contents which are more personalized and relevant to their users.\n",
    "\n",
    "In this lab, we shall build a straightforward recommender system taking advantage of a graph analysis. In graph data, information is stored as nodes, which are linked together by edges. This allows to easily retrieve knowledge about relationships between nodes. Therefore, graphs are useful to describe systems of strongly connected entities, such as social networks or metro networks for example. Following shows an example of movie ratings by a specific user for different movies he has purchased, viewed in the form of graph. [Click here to see more on this experiment](https://www.kernix.com/blog/an-efficient-recommender-system-based-on-graph-database_p9). We shall build a similar system later in the course with a much bigger and complex dataset. \n",
    "\n",
    "\n",
    "<img src=\"rs1.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Co-purchase Dataset\n",
    "\n",
    "\n",
    "This project will use Amazon Meta-Data Set maintained on the Stanford Network Analysis Project (SNAP) website. The data was collected by crawling Amazon website and contains product metadata and review information about 548,552 different products (Books, music CDs, DVDs and VHS video tapes). [Click here to visit the official site](https://snap.stanford.edu/data/amazon-meta.html). This and other similar datasets have been used massively for marketing analytics, customer segmentations and building recommendation systems. \n",
    "\n",
    "\n",
    "The following information is available for each product in this dataset:\n",
    "- __Id: Product id (number 0, ..., 548551)__\n",
    "\n",
    "\n",
    "- __ASIN: Amazon Standard Identification Number. __\n",
    "\n",
    "The Amazon Standard Identification Number (ASIN) is a 10-character alphanumeric unique identifier assigned by Amazon.com for product identification. You can lookup products by ASIN using following link: https://www.amazon.com/product-reviews/<ASIN> \n",
    "\n",
    "- __Title: Name/title of the product__\n",
    "\n",
    "\n",
    "- __Group: Product group.__ \n",
    "\n",
    "The product group can be Book, DVD, Video or Music.\n",
    "- __Salesrank: Amazon Salesrank__\n",
    "\n",
    "The Amazon sales rank represents how a product is selling in comparison to other products in its primary category. The lower the rank, the better a product is selling. \n",
    "similar: ASINs of co-purchased products (people who buy X also buy Y)\n",
    "\n",
    "- __Categories: Location in product category__\n",
    "\n",
    "hierarchy to which the product belongs (separated by |, category id in [])\n",
    "- __Reviews: Product review information__ \n",
    "\n",
    "Total number of reviews, average rating, as well as individual customer review information including time, user id, rating, total number of votes on the review, total number of helpfulness votes (how many people found the review to be helpful)\n",
    "\n",
    "The data was collected in summer 2006.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing \n",
    "\n",
    "The Co-purchase meta dataset is almost 1GB in raw format as shown below:\n",
    "\n",
    "![](raw.png)\n",
    "\n",
    "Pre-processing involves reading and formatting this data for further analysis. This involves some use of parsing techniques with NLP etc. In order to keep our focus on the actual analysis ( and not the data engineering here), this data has been pre-processed for you as follows:\n",
    "\n",
    "- Parse the amazon-meta.txt file downloaded from the snap side. \n",
    "\n",
    "- Read the metadata for all ASINs, and write out the following fields into the `amazonProducts` Nested Dictionary. \n",
    "\n",
    "`amazonProducts = (key = ASIN : value = MetaData Dictionary associated with ASIN )`.\n",
    "\n",
    "- Filter data to include only books as `Group==Book`, and write filtered data to `amazonBooks` Dictionary\n",
    "\n",
    "- Use the co-purchase data in `amazonBooks` Dictionary to create the `copurchaseGraph` Structure as follows:\n",
    "\n",
    "    - __Nodes__: the ASINs are Nodes in the Graph\n",
    "    - __Edges__: an Edge exists between two Nodes (ASINs) if the two ASINs were co-purchased\n",
    "    - __Edge Weight (based on Category Similarity)__: since we are attempting to make book recommendations based on co-purchase information, it would be nice to have some measure of Similarity for each ASIN (Node) pair that was co-purchased (existence of Edge between the Nodes). We can then use the Similarity measure as the Edge Weight between the Node pair that was co-purchased. We can potentially create such a Similarity measure by using the “Categories” data, where the Similarity measure between any two ASINs that were co-purchased is calculated as follows:\n",
    "    - __Similarity__ = (Number of words that are common between Categories of connected Nodes)/\n",
    "            (Total Number of words in both Categories of connected Nodes)\n",
    "    The Similarity ranges from 0 (most dissimilar) to 1 (most similar).\n",
    "\n",
    "    Add the following graph-related measures for each ASIN to the amazonBooks Dictionary:\n",
    "    - __DegreeCentrality__: associated with each Node (ASIN)\n",
    "    - __ClusteringCoeff__: associated with each Node (ASIN)\n",
    "\n",
    "- Write out the a`mazonBooks` data to the `amazon-books.txt` file\n",
    "\n",
    "- Write out the `copurchaseGraph` data to the `amazon-books-copurchase.edgelist` file\n",
    "\n",
    ">The following preprocessed data files have been provided in the repo for this analysis. \n",
    "\n",
    "- `amazon-books.txt`\n",
    "- `amazon-books-copurchase.edgelist`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Files into python environment \n",
    "\n",
    "- Let's first import the necessary libraries we need for this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Read amazon-books.txt data into `books_dict`  Dictionary\n",
    "\n",
    "- Set ASIN as they key for each dictionary entry and Metadata as value. The metadata should contain following entries from original data.\n",
    "\n",
    "- MetaData\n",
    "\n",
    "    - Id\n",
    "    - Title\n",
    "    - Ctagories\n",
    "    - Group\n",
    "    - SalesRank\n",
    "    - TotalReviews\n",
    "    - AvgRatings\n",
    "    - DegreeCentrality\n",
    "    - ClusteringCoeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from the amazon-books.txt and populate nested dicitonary:\n",
    "# key = ASIN; value = MetaData associated with ASIN\n",
    "\n",
    "# Code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393561"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the total number of records - uncomment to run\n",
    "\n",
    "# len(books_dict) \n",
    "\n",
    "# 393561"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read `amazon-books-copurchase.edgelist` into the `books_copurchase_graph` \n",
    "\n",
    "- Open the edge list file in read only mode\n",
    "- Read the edge list into a networkx weighted graph using `nx.read_weighted_edgelist()`\n",
    "- Print he information about the graph using `nx.info(G)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 270347\n",
      "Number of edges: 741124\n",
      "Average degree:   5.4828\n"
     ]
    }
   ],
   "source": [
    "# Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have quiet a lot of books with even higher number of co purchasing links (edges) between them as we can see here. Trying to visualize this may be an exercise in vain, unless we filter the data by groups/categories of books."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Make A Purchase\n",
    "\n",
    "Recommendation systems need initial set of data to actually make future recommendations around products, services or new edges (firends in a social network). For this, we need to select at least one book from the data and work of generating recommendations based on that purchase. You can refer to the `amazon-books.txt` and select a first purchase there. As we are using ASIN as a key to our books dictionary, we would need an ASIN to simulate a purchase.  \n",
    "\n",
    "- For this experiment, lets purchase the popular sci-fi novel \"War of the Worlds\" that has `ASIN = 0486405524`. Use this asin to print title, salesRank, total reviews, average ratings , degree centrality and clustering coefficient for this. item "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My First Purchase\n",
      "-----------------\n",
      "Title =  The War of the Worlds (Dover Children's Thrift Classics)\n",
      "ASIN =  0486405524\n",
      "SalesRank =  990009\n",
      "TotalReviews =  186\n",
      "AvgRating =  4.0\n",
      "DegreeCentrality =  5\n",
      "ClusteringCoeff =  0.84\n"
     ]
    }
   ],
   "source": [
    "# Select an ASIN as first purchase - \n",
    "# You are welcome to use your own,  just make sure that asin is present in the books file and it has some neighbors\n",
    "\n",
    "print (\"My First Purchase\")\n",
    "print (\"-----------------\")\n",
    "asin = '0486405524'\n",
    "\n",
    "# Print out the features associates with the book\n",
    "\n",
    " # Code here \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">__So how do we make other Book Recommendations with this purchase, based on the book co-purchase data that we have__?\n",
    "\n",
    "\n",
    "\n",
    "We could potentially take **ALL** books that were ever co-purchased with this book, and recommend all of them. We notice that this Book has a Degree Centrality of 5 i.e. 5 other Books were co-purchased with this Book by other customers. However, the Degree Centrality of Nodes in a product Co-Purchase Network can typically be pretty large, specially for a popular products. e.g. let's try `ASIN=0805047905`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brown Bear, Brown Bear, What Do You See?\n",
      "Degree Centrality: 216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create variable dcl from the copurchaseGraph data using the networkx.degree package \n",
    "# Create new variable dc is equal to dcl of given asin \n",
    "# print dc\n",
    "temp_asin = '0805047905'\n",
    "print(books_dict[temp_asin]['Title'])\n",
    "dcl = nx.degree(books_copurchase_graph)\n",
    "dc = dcl[temp_asin]\n",
    "print (\"Degree Centrality:\", dc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should therefore come up with a better strategy as we can't recommend 216 books with a single purchase, without any clear ordering and filtering.  So we will use __Ego Networks__. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in the Ego Network\n",
    "\n",
    "- Get the list books that have been co-purchased with the purchased book (War of the Worlds) in the past. i.e. get the **depth-1** ego network of purchased book from `books_copurchase_graph` using `nx.egograph()`.\n",
    "- Assign the resulting graph to `purchased_ego_graph`.\n",
    "- Inspect number of Nodes and Edges and in `purchased_ego_graph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ego Network: Nodes = 6 Edges = 12\n"
     ]
    }
   ],
   "source": [
    "# Get ego network of given asin at depth 1 using networkx.ego_graph package + assign to variable ego_graph\n",
    "# print number of nodes and edges in ego_graph\n",
    "\n",
    "ego_graph = None \n",
    "\n",
    "# Uncomment to run below\n",
    "\n",
    "# print (\"Ego Network:\", \n",
    "#       \"Nodes =\", ego.number_of_nodes(), \n",
    "#       \"Edges =\", ego.number_of_edges())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall now use island method on ego network with a threshold of 0.5 to trim down the ego network. You can experiment with the trim value to see the effect of selection of recommendations. For now, lets perform following steps:\n",
    "-  Set threshold value to 0.5\n",
    "\n",
    "\n",
    "- Create empty graph instance `trimmed_ego_net` using the `nx.Graph()`to represent the trimmed network\n",
    "\n",
    "\n",
    "- Iterate through the edge data (to, from, weight)  in `ego_graph`:\n",
    "\n",
    "    - if edge weight is greater than or equal to defined threshold:\n",
    "    \n",
    "        - add node 1, node 2, edge weight to the egotrim tuple\n",
    "        \n",
    "        \n",
    "- Print edges and nodes in the `trimmed_ego_net`\n",
    "\n",
    "- Print list of `trimmed_ego_net` network to obtain the asin of the books in the trimmed network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed Ego Network: \n",
      "____________________\n",
      " \n",
      "Threshold= 0.5 \n",
      "Nodes = 6 \n",
      "Edges = 10\n",
      "\n",
      "ASINs in the trimmed network: \n",
      " ['0812550927', '0140022651', '0812505042', '0553214322', '0486405524', '0486270718']\n"
     ]
    }
   ],
   "source": [
    "# Create empty graph instance `trimmed_ego_net` using the `nx.Graph()`to represent the trimmed network\n",
    "\n",
    "threshold = None\n",
    "trimmed_ego_net = None\n",
    "\n",
    "# Iterate\n",
    "\n",
    "# Code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great. We can now inspect the neighbor ASINs in our trimmed network as below:\n",
    "\n",
    "- Print out the neighbors of the asin in the trimmed network\n",
    "- Create variable called neighbors which contains the neighbors of the given asin in the trimmed network \n",
    "- print list of neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0812505042', '0553214322', '0486270718']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the neighbors of the asin in the trimmed network\n",
    "\n",
    "# code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Recommendations \n",
    "\n",
    "Great, we are almost there. We just need to use above ASINs to extract actual book data that these ASINs represent, and that would be our recommendations. Perform following steps:\n",
    "- Iterate through the list of neighbors created above. \n",
    "- Use `books_dict` to extract following information for the dictionary \n",
    "    -  ASIN\n",
    "    - Title from the amazonBooks dataset\n",
    "    - AvgRating from the amazonBooks dataset\n",
    "    - TotalReviews from the amazonBooks dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purchased Book\n",
      "Title:  The War of the Worlds (Dover Children's Thrift Classics)\n",
      "\n",
      "Customers who bought this book, also bought\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "Asin:  0553214322\n",
      "Book Title:  The Island of Dr. Moreau (Bantam Classics)\n",
      "Average Rating: 4.0\n",
      "Number of Reviews:  54\n",
      "\n",
      "Asin:  0486270718\n",
      "Book Title:  The Invisible Man (Dover Thrift Editions)\n",
      "Average Rating: 3.5\n",
      "Number of Reviews:  21\n"
     ]
    }
   ],
   "source": [
    "# code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"rs.jpeg\" width=400>\n",
    "\n",
    "There we have it, our graph based recommendation system. We can see that network is attempting to recommend books that are very similar in taste to the original purchase. That is the beauty of Recommendation Systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up - Optional \n",
    "\n",
    "- Package above code into functions to simple pass in a book ASIN and get recommendations. \n",
    "- Use movie lens database with this approach to recommend movies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resouces\n",
    "\n",
    "This dataset used in this experiment was set up and introduced in the following paper focused at digital marketing. Although it is not mandatory, we would encourage you to read this paper to see how such products can become game changers for a number of data driven businesses.\n",
    "\n",
    "http://www.cs.cmu.edu/~jure/pubs/viral-tweb.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "In this lab, we built a recommendation system using Graph analysis techniques that we covered in this section. This is a simple recommendation system and can be improved a lot by bringing in more data i.e. user reviews, categories of books and in some cases, some manual fine tuning to create custom edges promoting recommendations. We shall look at another technique called collaborative filtering later in the course where we shall try to expand upon this experiment. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
